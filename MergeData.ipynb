{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 1 : Chargement des données prétraitées\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data(article_path, dispo_path, tiers_path, ligne_path, piece_path, depot_path, remise_path):\n",
    "    \"\"\"\n",
    "    Charge les données prétraitées des tables ARTICLE, DISPO, TIERS, LIGNE, PIECE, DEPOT, et REMISE.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        article = pd.read_csv(article_path)\n",
    "        dispo = pd.read_csv(dispo_path)\n",
    "        tiers = pd.read_csv(tiers_path)\n",
    "        ligne = pd.read_csv(ligne_path)\n",
    "        piece = pd.read_csv(piece_path)\n",
    "        depot = pd.read_csv(depot_path)\n",
    "        remise = pd.read_csv(remise_path)\n",
    "        print(\"Données prétraitées chargées avec succès.\")\n",
    "        return article, dispo, tiers, ligne, piece, depot, remise\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement des données : {e}\")\n",
    "        return None, None, None, None, None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 2 : Fusionner les données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(article, dispo, tiers, ligne, piece, depot, remise):\n",
    "    \"\"\"\n",
    "    Fusionne les tables ARTICLE, DISPO, TIERS, LIGNE, PIECE, DEPOT, et REMISE en utilisant les relations définies.\n",
    "    \"\"\"\n",
    "    # Jointure entre ARTICLE et DISPO\n",
    "    merged_data = pd.merge(article, dispo, left_on=\"GA_ARTICLE\", right_on=\"GQ_ARTICLE\", how=\"left\")\n",
    "    print(\"Jointure entre ARTICLE et DISPO terminée.\")\n",
    "\n",
    "    # Jointure entre le résultat précédent et TIERS\n",
    "    merged_data = pd.merge(merged_data, tiers, left_on=\"GA_FOURNPRINC\", right_on=\"T_AUXILIAIRE\", how=\"left\")\n",
    "    print(\"Jointure entre ARTICLE+DISPO et TIERS terminée.\")\n",
    "\n",
    "    # Jointure avec LIGNE\n",
    "    merged_data = pd.merge(merged_data, ligne, left_on=\"GA_ARTICLE\", right_on=\"GL_ARTICLE\", how=\"left\")\n",
    "    print(\"Jointure avec LIGNE terminée.\")\n",
    "\n",
    "    # Jointure avec PIECE\n",
    "    merged_data = pd.merge(merged_data, piece, left_on=\"GL_NUMERO\", right_on=\"GP_NUMERO\", how=\"left\")\n",
    "    print(\"Jointure avec PIECE terminée.\")\n",
    "\n",
    "    # Jointure avec DEPOT\n",
    "    merged_data = pd.merge(merged_data, depot, left_on=\"GL_DEPOT\", right_on=\"GDE_DEPOT\", how=\"left\")\n",
    "    print(\"Jointure avec DEPOT terminée.\")\n",
    "\n",
    "    # Jointure avec REMISE\n",
    "    merged_data = pd.merge(merged_data, remise, left_on=[\"GL_NUMERO\", \"GL_NUMLIGNE\"], right_on=[\"MLR_NUMERO\", \"MLR_NUMLIGNE\"], how=\"left\")\n",
    "    print(\"Jointure avec REMISE terminée.\")\n",
    "\n",
    "    print(f\"Taille de la table fusionnée : {merged_data.shape}\")\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 3 : Sauvegarder la table finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_merged_data(data, output_path):\n",
    "    \"\"\"\n",
    "    Sauvegarde la table fusionnée dans un fichier CSV.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data.to_csv(output_path, index=False)\n",
    "        print(f\"Données fusionnées sauvegardées dans '{output_path}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la sauvegarde des données : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline principal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_tables(article_path, dispo_path, tiers_path, ligne_path, piece_path, depot_path, remise_path, output_path):\n",
    "    \"\"\"\n",
    "    Concatène les tables ARTICLE, DISPO, TIERS, LIGNE, PIECE, DEPOT, et REMISE en une seule table.\n",
    "    \"\"\"\n",
    "    # Étape 1 : Chargement des données prétraitées\n",
    "    article, dispo, tiers, ligne, piece, depot, remise = load_preprocessed_data(\n",
    "        article_path, dispo_path, tiers_path, ligne_path, piece_path, depot_path, remise_path\n",
    "    )\n",
    "    if any(table is None for table in [article, dispo, tiers, ligne, piece, depot, remise]):\n",
    "        return None\n",
    "\n",
    "    # Étape 2 : Fusionner les données\n",
    "    merged_data = merge_data(article, dispo, tiers, ligne, piece, depot, remise)\n",
    "\n",
    "    # Étape 3 : Sauvegarder la table finale\n",
    "    save_merged_data(merged_data, output_path)\n",
    "\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exécution du pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur lors du chargement des données : [Errno 2] No such file or directory: 'ArticlePreprocessed.csv'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Chemins vers les fichiers prétraités\n",
    "    article_path = \"ArticlePreprocessed.csv\"\n",
    "    dispo_path = \"DISPO_Preprocessed.csv\"\n",
    "    tiers_path = \"TIERS_Preprocessed.csv\"\n",
    "    ligne_path = \"Ligne_Preprocessed.csv\"\n",
    "    piece_path = \"Piece_Preprocessed.csv\"\n",
    "    depot_path = \"Depot_Preprocessed.csv\"\n",
    "    remise_path = \"Remise_Preprocessed.csv\"\n",
    "\n",
    "    # Chemin de sortie pour la table fusionnée\n",
    "    output_path = \"Concatenated_Data.csv\"\n",
    "\n",
    "    # Concaténer les tables\n",
    "    concatenated_data = concatenate_tables(\n",
    "        article_path, dispo_path, tiers_path, ligne_path, piece_path, depot_path, remise_path, output_path\n",
    "    )\n",
    "\n",
    "    # Afficher un aperçu des données fusionnées\n",
    "    if concatenated_data is not None:\n",
    "        print(concatenated_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
